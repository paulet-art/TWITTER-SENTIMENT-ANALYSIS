{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TWITTER SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary modules\n",
    "import pyforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the data\n",
    "df = pd.read_csv(r\"C:\\Users\\User\\Documents\\training.1600000.processed.noemoticon.csv\", encoding=\"ISO-8859-1\", header=None )\n",
    "df = df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "df.columns = ['sentiment_value','id','date','query','user','tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BASIC EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_value'].value_counts().sort_index()\\\n",
    "     .plot(kind='bar', title='Sentiment Value Counts')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK PROCESSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display tweet\n",
    "example = df['tweet'][50]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize tweet\n",
    "tokens = nltk.word_tokenize(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part of speech tagging\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "tagged[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#groups tokens\n",
    "entities = nltk.chunk.ne_chunk(tagged)\n",
    "entities.pprint()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VADER SENTIMENT SCORING\n",
    "\n",
    "We use VADER from NLTK to get the negative, neutral and positive sentiments of the tweets\n",
    "- stop words (eg 'and', 'the') are removed \n",
    "- each word is scored and total scores combined\n",
    "- does not account of relationships between words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test sia on a text\n",
    "sia.polarity_scores('I am happy!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test sia on a text\n",
    "sia.polarity_scores('I am sad!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply on tweet\n",
    "sia.polarity_scores(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply sia on all tweets\n",
    "res = {}\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    text = row['tweet']\n",
    "    myid = row['id']\n",
    "    res[myid] = sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaders = pd.DataFrame(res).T\n",
    "vaders = vaders.reset_index().rename(columns={'index': 'id'})\n",
    "vaders = vaders.merge(df, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment score and metadata\n",
    "vaders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plout vader results\n",
    "ax = sns.barplot(data=vaders, x='sentiment_value', y='compound')\n",
    "ax.set_title(\"Compound Score by Tweet Sentiment\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=vaders, x='sentiment_value', y='neg')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROBERTA PRE-TRAINED MODEL\n",
    "\n",
    "-Model trained on large data\n",
    "\n",
    "-accounts for words and and context too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install requirements\n",
    "%pip install transformers\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install model\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test roberta model\n",
    "encoded = tokenizer(example, return_tensors = 'pt')\n",
    "output = model(**encoded)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "scores_dict = {\n",
    "    'negative': scores[0],\n",
    "    'neutral': scores[1],\n",
    "    'positive' : scores[2]\n",
    "}\n",
    "print(scores_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate over tweets\n",
    "def polarity_scores_roberta(example):\n",
    "    encoded = tokenizer(example, return_tensors = 'pt')\n",
    "    output = model(**encoded)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    scores_dict = {\n",
    "        'negative': scores[0],\n",
    "        'neutral': scores[1],\n",
    "        'positive' : scores[2]\n",
    "    }\n",
    "    return scores_dict\n",
    "print(scores_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply roberta on all tweets \n",
    "res = {}\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    text = row['tweet']\n",
    "    myid = row['id']\n",
    "    vader_results = sia.polarity_scores(text)\n",
    "    vader_results_rename = {}\n",
    "    for key, value in vader_results.items():\n",
    "        vader_results_rename[f'vader_{key}'] = value\n",
    "    roberta_results = polarity_scores_roberta(text)\n",
    "    both = {**vader_results, **roberta_results}\n",
    "    res[myid] = both\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(res).T \n",
    "result_df = result_df.reset_index().rename(columns={'index': 'id'})\n",
    "result_df = result_df.merge(df, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAIVE BAYES CLASSIFIER SENTIMENT ANALYSIS WITH ML MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_two = pd.read_csv(r\"C:\\Users\\User\\Documents\\training.1600000.processed.noemoticon.csv\", encoding=\"ISO-8859-1\", header=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_two.columns = ['sentiment_value','id','date','query','user','tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex\n",
    "import re\n",
    "\n",
    "def preprocess(tweet):\n",
    "    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n",
    "    # Remove mentions\n",
    "    tweet = re.sub(r\"@\\w+\", \"\", tweet)\n",
    "    # Remove special characters\n",
    "    tweet = re.sub(r\"[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \", tweet)\n",
    "    # Lowercase the text\n",
    "    tweet = tweet.lower()\n",
    "    return tweet\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df_two = df[[\"sentiment_value\", \"tweet\"]]\n",
    "\n",
    "# Replace target values with labels\n",
    "df_two[\"tweet\"] = df[\"tweet\"].replace({0: \"negative\", 4: \"positive\"})\n",
    "\n",
    "# Apply preprocess to the text column\n",
    "df_two[\"tweet\"] = df[\"tweet\"].apply(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_two.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"tweet\"], df[\"sentiment_value\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_features = vectorizer.fit_transform(X_train)\n",
    "X_test_features = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.score(X_test_features, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
